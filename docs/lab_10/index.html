<!DOCTYPE html>
<html lang="en">

<head>
    <title>Lab 10 - Localization (Sim) | Michael Crum's Portfolio</title>

    <!-- seo -->
    <meta name="author" content="Michael Crum">
    <meta name="description" content="Page for lab 10">
    <meta name="keywords" content="portfolio,developer,robotics,personal">

    <!-- display -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- icon -->
    <link rel="icon" type="image/png" sizes="32x32" href="../global_assets/icons/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="../global_assets/icons/favicon-16x16.png" />

    <!-- stylesheets -->
    <link rel="stylesheet" href="../styles/project_page.css">
    <link rel="stylesheet" href="../styles/highlight/styles/base16/bright.min.css">
    <link rel="stylesheet" href="../styles/katex/katex.min.css">

    <!-- syntax highlighting-->
    <script src="../styles/highlight/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <!-- latex support-->
    <script defer src="../styles/katex/katex.min.js"></script>

    <!-- font -->
    <link href="https://fonts.googleapis.com/css2?family=Pacifico&display=swap" rel="stylesheet" />
</head>

<body>
    <script src="../styles/themes/prism.js"></script>
    <div id="left_pad"></div>
    <aside>
        <h1><a href="..">Fast Robots</a></h1>
        <h3><em>Lab Reports:</em></h3>
        <nav>
            <ul>
                <li>
    <a href="../intro">
        <img src="../intro/assets/snapshot.webp" alt="Introduction">
        <div>
            <p>Introduction</p>
            <em> 1.27.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_1">
        <img src="../lab_1/assets/snapshot.webp" alt="Lab 1 - Artemis">
        <div>
            <p>Lab 1 - Artemis</p>
            <em> 1.27.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_2">
        <img src="../lab_2/assets/snapshot.webp" alt="Lab 2 - Bluetooth Communication">
        <div>
            <p>Lab 2 - Bluetooth Communication</p>
            <em> 2.2.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_3">
        <img src="../lab_3/assets/snapshot.webp" alt="Lab 3 - Time Of Flight (ToF)">
        <div>
            <p>Lab 3 - Time Of Flight (ToF)</p>
            <em> 2.9.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_4">
        <img src="../lab_4/assets/snapshot.webp" alt="Lab 4 - IMU">
        <div>
            <p>Lab 4 - IMU</p>
            <em> 2.16.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_5">
        <img src="../lab_5/assets/snapshot.webp" alt="Lab 5 - Motors and Open Loop Control">
        <div>
            <p>Lab 5 - Motors and Open Loop Control</p>
            <em> 2.23.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_6">
        <img src="../lab_6/assets/snapshot.webp" alt="Lab 6 - PID Orientation Control">
        <div>
            <p>Lab 6 - PID Orientation Control</p>
            <em> 3.9.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_7">
        <img src="../lab_7/assets/snapshot.webp" alt="Lab 7 - Kalman Filter">
        <div>
            <p>Lab 7 - Kalman Filter</p>
            <em> 3.16.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_8">
        <img src="../lab_8/assets/snapshot.webp" alt="Lab 8 - Stunts!">
        <div>
            <p>Lab 8 - Stunts!</p>
            <em> 3.23.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_9">
        <img src="../lab_9/assets/snapshot.webp" alt="Lab 9 - Mapping">
        <div>
            <p>Lab 9 - Mapping</p>
            <em> 4.13.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_10">
        <img src="../lab_10/assets/snapshot.webp" alt="Lab 10 - Localization (Sim)">
        <div>
            <p>Lab 10 - Localization (Sim)</p>
            <em> 4.20.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_11">
        <img src="../lab_11/assets/snapshot.webp" alt="Lab 11 - Localization (Real)">
        <div>
            <p>Lab 11 - Localization (Real)</p>
            <em> 4.27.23</em>
        </div>
    </a>
</li>
<li>
    <a href="../lab_12">
        <img src="../lab_12/assets/snapshot.webp" alt="Lab 12 - Path Planning and Execution">
        <div>
            <p>Lab 12 - Path Planning and Execution</p>
            <em> 5.4.23</em>
        </div>
    </a>
</li>
            </ul>
        </nav>
    </aside>
    <article id="article">
        <h1>
            Lab 10 - Localization (Sim)
        </h1>
        <em class="date">
            4.20.23
        </em>
        <br>
        <h2>Introduction</h2>
<p>In this lab I used a bayes filter to localize the robot in a simulated environment.</p>
<h2>Prelab</h2>
<p>Before attempting the lab, I needed to get the simulator running on my computer. I followed the <a href="https://cei-lab.github.io/FastRobots-2023/FastRobots-Sim.html">installation instructions</a> for the Ubuntu partition on my laptop. The only issue I encountered was Ubuntu complaining that the Box2D pip wheel didn't support my OS, so I just installed from source. With the simulator running, I learned about the functions by implementing closed loop wall avoidance. Because my real robot has two sensors to the front of the robot, I edited /config/world.yml to include two sensors:</p>
<pre><code class="language-yaml"># Specify the angles (in a counter-clockwise direction) for the ToF sensor(s) where 0 degrees is at the robot's heading
angles: 
    - -20
    - 20
</code></pre>
<p>Below is my code and a video showing the results.</p>
<pre><code class="language-python">cmdr.reset_plotter()
cmdr.reset_sim()

while cmdr.sim_is_running() and cmdr.plotter_is_running():
    pose, gt_pose = cmdr.get_pose()
    cmdr.plot_odom(pose[0], pose[1])
    cmdr.plot_gt(gt_pose[0], gt_pose[1])
    
    dist_right = cmdr.get_sensor()[0]
    right_contrib = -0.5/(dist_right * dist_right)
    dist_left = cmdr.get_sensor()[1]
    left_contrib = -0.5/(dist_left * dist_left)
    
    cmdr.set_vel(1, right_contrib + left_contrib)
</code></pre>
<iframe width="492" height="875" src="https://www.youtube.com/embed/HD-ApRYbShs" title="ECE 4160 - Closed Loop Sim Control" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<h2>Theory Behind the Bayes Filter</h2>
<p>The Bayes Filter is a probabilistic approach that calculates the distribution of some quantity over a discretized state space. In this case the quantity is the robot's pose (x, y, theta) and the discretized space is the map divided into 1 m squares with possible poses divided every 20 degrees. This translates into a 3D grid of size (12, 9, 19), which is small enough to compute over fully.</p>
<p>The Bayes filter algorithm is as follows:</p>
<p><img src="./assets/bayes_filter.webp" alt="The Bayes Filter"></p>
<p>Where <eq><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>e</mi><mi>l</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">bel(x_{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></eq> is the belief distribution before running the filter,
<eq><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">u_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></eq> is the commands we gave the robot in this time-step,
and <eq><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></eq> is the sensor measurements for this time-step.</p>
<p>The filter iterates over every pose <eq><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></eq> and computes the probably that it's the true pose given the input variables. The first step is the prediction step, which finds how likely the state is given the previous state and our command. If we tell the car to move forward, we would expect the car to execute that command and actually move according to our understanding of it's dynamics. This should cause the distribution to move accordingly, and is factored into the calculation.</p>
<p>Using only the update step is equivalent to relying entirely on odometry, which previous experiments have shown is an unreliable approach. To solve this problem, we integrate the update step. The update step uses sensor measurements and a sensor model to compare the predicted sensor measurements for <eq><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></eq> to the observed values. The result is a probability representing how likely it is that the sensor measurements were taken from that pose.</p>
<h2>Fixing an Issue With the Sim</h2>
<p>An oversight in the simulator results in mapper.get_views not respecting custom sensor arrangements. Regardless of sensor configuration, the function caches data from a single sensor pointed straight forward.</p>
<p>I edited the mapper class to respect the sensor configuration, with the most notable edit to the get_views method:</p>
<pre><code class="language-python">for j in range(0, self.SENSOR_COUNT):
    # Calculate bearings and tracing rays
    bearings = np.arange(
        0, 360, self.RAY_TRACING_ANGLE_INCREMENT) + pose[2] + self.SENSOR_ANGLES[j]
</code></pre>
<p>The full localization.py file with relevant fixes can be <a href="https://github.com/usedhondacivic/FAST-ROBOTS-2023/blob/main/FastRobots-sim-release/localization.py">found here</a>.</p>
<h2>Implementing the Bayes Filter in Python</h2>
<p>I used <a href="https://lyl24.github.io/lyl24-ece4960/lab11">Linda Li's</a> implementation of the sensor model, movement model, and update / prediction step. I updated the model for my specific sensor arrangement, but unless noted the code was written by her.</p>
<p>The compute_control function takes the movement over a time step and converts it into the control command that would have caused the motion:</p>
<pre><code class="language-python">def compute_control(cur_pose, prev_pose):
    &quot;&quot;&quot;
    Args:
        cur_pose  ([Pose]): Current Pose
        prev_pose ([Pose]): Previous Pose 

    Returns:
        [delta_rot_1]: Rotation 1  (degrees)
        [delta_trans]: Translation (meters)
        [delta_rot_2]: Rotation 2  (degrees)
    &quot;&quot;&quot;
    
    cur_x, cur_y, cur_theta = cur_pose
    prev_x, prev_y, prev_theta = prev_pose
    
    degrees = np.degrees(np.arctan2(cur_y - prev_y, cur_x - prev_x))
    delta_rot_1 = loc.mapper.normalize_angle(degrees - prev_theta)
    delta_trans = np.sqrt((cur_pose[0]-prev_pose[0])**2+(cur_pose[1]-prev_pose[1])**2)
    delta_rot_2 = loc.mapper.normalize_angle(cur_theta - prev_theta - delta_rot_1)
    
    return delta_rot_1, delta_trans, delta_rot_2
</code></pre>
<p>This is useful because we never directly record our robot commands. We can instead observe the robots behavior and infer the commands after the fact.</p>
<p>These commands are used in the odometry model to predict the probability that the robot has reached a given state based on where it was before and what we told it to do.</p>
<pre><code class="language-python">def odom_motion_model(cur_pose, prev_pose, u):
    &quot;&quot;&quot;
    Args:
        cur_pose  ([Pose]): Current Pose
        prev_pose ([Pose]): Previous Pose
        (rot1, trans, rot2) (float, float, float): A tuple with control data in the format 
                                                   format (rot1, trans, rot2) with units (degrees, meters, degrees)

    Returns:
        prob [float]: Probability p(x'|x, u)
    &quot;&quot;&quot;
    
    rot1, trans, rot2 = compute_control(cur_pose, prev_pose) #actual movement
    rot1_u, trans_u, rot2_u = u #inputted movement

    rot1_prob = loc.gaussian(rot1, rot1_u, loc.odom_rot_sigma)
    trans_prob = loc.gaussian(trans, trans_u, loc.odom_trans_sigma)
    rot2_prob = loc.gaussian(rot2, rot2_u, loc.odom_rot_sigma)
    prob = rot1_prob*trans_prob*rot2_prob

    return prob
</code></pre>
<p>All of these predictions are integrated by the prediction step:</p>
<pre><code class="language-python">def prediction_step(cur_odom, prev_odom):
    &quot;&quot;&quot; 
    Args:
        cur_odom  ([Pose]): Current Pose
        prev_odom ([Pose]): Previous Pose
    &quot;&quot;&quot;
    
    u = compute_control(cur_odom, prev_odom)
    for x_prev in range(MAX_CELLS_X):
        for y_prev in range(MAX_CELLS_Y):
            for theta_prev in range(MAX_CELLS_A):
                if loc.bel[(x_prev, y_prev, theta_prev)] &lt; 0.0001:
                    continue
                for x_cur in range(MAX_CELLS_X):
                    for y_cur in range(MAX_CELLS_Y):
                        for theta_cur in range(MAX_CELLS_A):
                            loc.bel_bar[(x_cur, y_cur, theta_cur)] += odom_motion_model(loc.mapper.from_map(x_cur, y_cur, theta_cur), loc.mapper.from_map(x_prev, y_prev, theta_prev), u)*loc.bel[(x_prev, y_prev, theta_prev)]
  
    loc.bel_bar = loc.bel_bar/np.sum(loc.bel_bar)
</code></pre>
<p>This step integrates the odometry prediction and the noise values associated with it to predict the new location and update beliefs accordingly.</p>
<p>Odometry is not enough to form an accurate prediction, so we update it with the data collected by the sensors:</p>
<pre><code class="language-python">def sensor_model(obs, cur_pose):
    &quot;&quot;&quot; 
    Args:
        obs ([ndarray]): A 2D array consisting of the measurements made in rotation loop

    Returns:
        [ndarray]: Returns a 1D array of size 18 (=loc.OBS_PER_CELL) with the likelihood of each individual measurements
    &quot;&quot;&quot;
    
    prob_array = []
    for i in range(18):
        prob_value_a = loc.gaussian(obs[i, 0], cur_pose[i, 0], loc.sensor_sigma)
        prob_value_b = loc.gaussian(obs[i, 1], cur_pose[i, 1], loc.sensor_sigma)
        prob_array.append(prob_value_a * prob_value_b)
    return prob_array

def update_step():
    for x in range(0, MAX_CELLS_X):
        for y in range(0, MAX_CELLS_Y):
            for theta in range(0, MAX_CELLS_A):
                loc.bel[(x, y, theta)] = np.prod(sensor_model(loc.obs_range_data,mapper.get_views(x, y, theta)))*loc.bel_bar[(x, y, theta)]

    loc.bel = loc.bel/np.sum(loc.bel) 
</code></pre>
<p>I updated Linda's sensor model to account for my two sensors in the sensor model. To simplify calculations I assumed that both sensor readings are independent, meaning that their joint probability is the product of their individual probabilities.</p>
<p>The update step updates our prediction by taking the product of our predicted belief with the probability that the sensor readings resulted from the predicted pose.</p>
<h2>Results</h2>
<p>Here's the Bayes filter running on a robot moving in a deterministic trajectory.</p>
<iframe width="1253" height="705" src="https://www.youtube.com/embed/H-z7aL3v3xA?start=15" title="ECE 4160 - Bayes Filter" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
<p>The filter predicts the correct location within one grid cell for almost all time steps. Initially it has difficulty determining which way the robot goes because of the symmetry of the left and right paths, but quickly converges on the correct location.</p>
<p>In highly symmetric environments, sensor readings are not uniquely correlated with the pose they are taken from. That is to say, two (or more) locations might generate the same probability from the sensor update step but be very far apart. Therefore, the Bayes Filter works much better in asymmetric environments.</p>

    </article>
    <div id="right_pad"></div>
</body>

</html>